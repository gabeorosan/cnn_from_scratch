{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0abb04ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "train, test = tf.keras.datasets.cifar10.load_data()\n",
    "x_train, y_train = train[0], train[1]\n",
    "x_test, y_test = test[0], test[1]\n",
    "\n",
    "class LinearLayer:\n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.input = x\n",
    "        self.output = x.dot(self.weights)\n",
    "        return self.output\n",
    "        \n",
    "    def update(self, dloss_dw, lr):\n",
    "        self.weights = self.weights - lr*dloss_dw\n",
    "    \n",
    "    def __init__(self, layer):\n",
    "        self.weights = layer\n",
    "        \n",
    "class ConvLayer:\n",
    "    \n",
    "    def convolve(self, x):\n",
    "        f = self.filter\n",
    "        fn, fd, fr, fc = f.shape\n",
    "        xn, xd, xr, xc = x.shape\n",
    "        x_pad = (fr - 1) // 2\n",
    "        y_pad = (fc - 1) // 2\n",
    "        x = np.pad(x, ((0, 0), (0, 0), (x_pad, x_pad), (y_pad, y_pad)))\n",
    "        o = np.zeros((xn, fn, xr, xc))\n",
    "        for r in range(xr):\n",
    "            for c in range(xc):\n",
    "                for n in range(fn):\n",
    "                    fm = f[n]\n",
    "                    xm = x[:, :, r:r+fr, c:c+fc]\n",
    "                    res = fm * xm\n",
    "                    o[:, n, r, c] += np.sum(np.sum(res, (2, 3)), 1)\n",
    "        return o\n",
    "    \n",
    "    def maxpool(self, x):\n",
    "        \n",
    "        xn, d, xr, xc = x.shape\n",
    "        o = np.zeros((xn, d, xr//2, xc//2))\n",
    "        ix = np.zeros_like(x)\n",
    "        for n in range(xn):\n",
    "            for r in range(0, xr, 2):\n",
    "                for c in range(0, xc, 2):\n",
    "                    m = np.amax(x[n, :, r:r+2, c:c+2], (1, 2))\n",
    "                    o[n, :, r//2, c//2] = m\n",
    "                    \n",
    "                    mm = x[n, :, r:r+2, c:c+2].reshape(d, 2*2)\n",
    "                    im = np.zeros_like(mm)\n",
    "                    \n",
    "                    im[range(d), np.argmax(mm, 1)] = 1\n",
    "                    im = im*(np.all(mm==0, 1)==0).reshape(-1, 1)\n",
    "                    \n",
    "                    ix[n, :, r:r+2, c:c+2] = im.reshape((d, 2, 2))\n",
    "                    if n ==0 and r==5 and c==5:\n",
    "                        print(ix[n, :, r:r+2, c:c+2])\n",
    "        self.ixs.append(ix)\n",
    "        \n",
    "        return o\n",
    "        \n",
    "    \n",
    "    def backpool(self, x):\n",
    "        self.backpool_inputs.append(x)\n",
    "        ix = self.ixs.pop()\n",
    "        xn, d, xr, xc = x.shape\n",
    "        result = np.zeros_like(ix)\n",
    "\n",
    "        for n in range(xn):\n",
    "            for r in range(xr):\n",
    "                for c in range(xc):\n",
    "                    xm = x[n, :, r, c].reshape(d, 1, 1)\n",
    "                    fm = ix[n, :, r*2:r*2+2, c*2:c*2+2]\n",
    "\n",
    "                    result[n, :, r*2:r*2+2, c*2:c*2+2] = xm*fm\n",
    "        self.backpool_results.append(result)  \n",
    "        return result * (self.relu_o>0)\n",
    "\n",
    "    def do_df(self, f):\n",
    "        \n",
    "        x = self.input\n",
    "    \n",
    "        fn, fd, fr, fc  = f.shape\n",
    "        xn, xd, xr, xc = x.shape\n",
    "        x_pad = (self.filter.shape[2] - 1) // 2\n",
    "        y_pad = (self.filter.shape[3] - 1) // 2\n",
    "        x = np.pad(x, ((0, 0), (0, 0), (x_pad, x_pad), (y_pad, y_pad)))\n",
    "        result = np.zeros_like(self.filter)\n",
    "        \n",
    "        for r in range(self.filter.shape[2]):\n",
    "            for c in range(self.filter.shape[3]):\n",
    "\n",
    "                xm = np.swapaxes(np.swapaxes(x[:, :, r:r+fr, c:c+fc], 0, 1).reshape((xd, -1)), 0, 1)\n",
    "                fm = np.swapaxes(f, 0, 1).reshape((fd, -1))\n",
    "                result[:, :, r, c] = fm @ xm\n",
    "                    \n",
    "        return result\n",
    "\n",
    "    def do_di(self, f):\n",
    "        \n",
    "        x = np.rot90(self.filter, k=2, axes=(2, 3))\n",
    "        \n",
    "        fn, fd, fr, fc = f.shape \n",
    "        xn, xd, xr, xc = x.shape \n",
    "        x_pad = fr - xr + (xr - 1) //2\n",
    "        y_pad = fc  - xc + (xc - 1) //2\n",
    "        x = np.pad(x, ((0, 0), (0, 0), (x_pad, x_pad), (y_pad, y_pad)))\n",
    "        result = np.zeros((fn, xd, fr, fc))\n",
    "        for n in range(fn):\n",
    "            for r in range(fr):\n",
    "                for c in range(fc):\n",
    "                    xm = np.swapaxes(x[:, :, r:r+fr, c:c+fc], 0, 1)\n",
    "                    fm = f[n]\n",
    "                    \n",
    "                    prod = xm * fm\n",
    "                    result[n, :, r, c] = np.sum(np.sum(prod, (2, 3)), 1)\n",
    "                    \n",
    "                    '''\n",
    "                    xm = np.swapaxes(x[:, :, r:r + fr, c:c+fc], 0, 1)\n",
    "                    res = xm * f[n]\n",
    "                    result[n, :, r, c] = np.sum(np.sum(res, (2, 3)), (1))\n",
    "                    '''\n",
    "                    \n",
    "        return np.rot90(result, k=2, axes=(2, 3))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.input= x\n",
    "        conv_o = self.convolve(x)\n",
    "        relu_o = np.maximum(conv_o, 0)\n",
    "        self.relu_o = relu_o\n",
    "        pool_o = self.maxpool(relu_o)\n",
    "        self.output = pool_o\n",
    "        return pool_o\n",
    "    \n",
    "    def backward(self, dloss_do):\n",
    "        o = self.backpool(dloss_do)\n",
    "        return self.do_df(o), self.do_di(o)\n",
    "    \n",
    "    def update(self, dloss_df, lr):\n",
    "        self.filter = self.filter - lr*dloss_df\n",
    "    \n",
    "    def __init__(self, layer):\n",
    "        self.backpool_results = []\n",
    "        self.backpool_inputs = []\n",
    "        self.filter = layer\n",
    "        self.ixs = []\n",
    "\n",
    "class CNN:\n",
    "\n",
    "    def NLLLoss(self, lsm, targets):\n",
    "        out = np.zeros_like(targets)\n",
    "        for i in range(targets.shape[0]): out[i] = lsm[i][targets[i]]\n",
    "        return -out.sum()/float(len(out))\n",
    "    \n",
    "    def log_softmax(self, x):\n",
    "        c = x.max()\n",
    "        logsumexp = np.log(np.exp(x - c).sum())\n",
    "        return x - c - logsumexp\n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.input = x\n",
    "        for l in self.conv_layers:\n",
    "            x = l.forward(x)\n",
    "        fcl_o = self.fcl.forward(x.reshape((1, -1)))\n",
    "        lsm = self.log_softmax(fcl_o)\n",
    "        return lsm\n",
    "    \n",
    "    def __init__(self, conv_layers, fcl_layer, learning_rate):\n",
    "        \n",
    "        self.conv_layers = conv_layers\n",
    "        self.fcl = fcl_layer\n",
    "        self.lr = learning_rate\n",
    "        \n",
    "    def eval(self, n):\n",
    "        \n",
    "        guesses, corr = [], []\n",
    "        for i in range(n):\n",
    "            \n",
    "            samp = np.random.randint(0, 50000)\n",
    "            shared_inp = np.asarray([x_train[samp]]).reshape((1, 3, 32, 32))\n",
    "            shared_out = [y_train[samp].item()]\n",
    "            \n",
    "            \n",
    "            p = self.forward(shared_inp)\n",
    "            my_pred = np.argmax(np.exp(p))\n",
    "            guesses.append(my_pred)\n",
    "            corr.append(shared_out[0])\n",
    "        return (np.asarray(guesses)==np.asarray(corr)).mean()\n",
    "        \n",
    "        \n",
    "    def backward(self, p, y):\n",
    "        \n",
    "        loss = self.NLLLoss(p, y)\n",
    "        out = np.zeros((y.shape[0],10))\n",
    "        out[range(out.shape[0]),y] = 1\n",
    "        d_out = -out / len(y)\n",
    "\n",
    "        dloss_dlsmi = d_out - np.exp(p)*d_out.sum(axis=1).reshape((-1, 1))\n",
    "        dloss_dfclo = dloss_dlsmi\n",
    "        \n",
    "        dloss_dfcli = self.fcl\n",
    "        \n",
    "        dfclo_dfcl = self.fcl.input\n",
    "        dloss_dfcl = np.dot(dfclo_dfcl.reshape((-1, 1)), dloss_dfclo.reshape(1, -1))\n",
    "        \n",
    "        dfclo_dfcli = self.fcl.weights\n",
    "        dloss_dfcli = np.dot(dfclo_dfcli, dloss_dfclo.reshape((-1, 1)))\n",
    "        \n",
    "        conv_layers = [l for l in self.conv_layers]\n",
    "        \n",
    "        dloss_do = dloss_dfcli.reshape((conv_layers[-1].output.shape))\n",
    "        dloss_dfcli = dloss_do\n",
    "        dloss_dfs = []\n",
    "        dloss_dos = []\n",
    "        \n",
    "        for i in range(len(conv_layers)):\n",
    "            layer = conv_layers.pop()\n",
    "            dloss_df, dloss_do = layer.backward(dloss_do)\n",
    "            dloss_dfs.append(dloss_df)\n",
    "            dloss_dos.append(dloss_do)\n",
    "            self.conv_layers[-(i+1)].update(dloss_df, self.lr)\n",
    "        self.fcl.update(dloss_dfcl, self.lr)\n",
    "        return dloss_dfclo, dloss_dfcli, dloss_dfcl, dloss_dfs, dloss_dos, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32ea19a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def fun(self, module,grad_in,grad_out):\n",
    "        \n",
    "        if grad_in[0] is not None: self.stored_gradients.append(grad_in[0])\n",
    "        self.stored_gradients.append(grad_out[0])\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.stored_gradients = []\n",
    "        self.ngpu=0\n",
    "        self.conv1 = nn.Conv2d(in_channels = 3, out_channels=16, kernel_size=5, stride=1, padding=2, bias=False)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(in_channels = 16, out_channels=20, kernel_size=5, stride=1, padding=2, bias=False)\n",
    "        self.conv3 = nn.Conv2d(in_channels = 20, out_channels=20, kernel_size=5, stride=1, padding=2, bias=False)\n",
    "        self.fcl = nn.Linear(4 * 4 * 20, 10)\n",
    "        self.lsm = nn.LogSoftmax(dim=1)\n",
    "        self.conv1.register_full_backward_hook(self.fun)\n",
    "        self.conv2.register_full_backward_hook(self.fun)\n",
    "        self.conv3.register_full_backward_hook(self.fun)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.stored_gradients = []\n",
    "        c1 = self.pool(F.relu(self.conv1(x)))\n",
    "        c1.retain_grad()\n",
    "        c2 = self.pool(F.relu(self.conv2(c1)))\n",
    "        c2.retain_grad()\n",
    "        c3 = self.pool(F.relu(self.conv3(c2)))\n",
    "        c3.retain_grad()\n",
    "        flat = torch.flatten(c3, 1) # flatten all dimensions except batch\n",
    "        flat.retain_grad()\n",
    "        fcl = self.fcl(flat)\n",
    "        fcl.retain_grad()\n",
    "        lsm = self.lsm(fcl)\n",
    "        lsm.retain_grad()\n",
    "        return lsm, fcl, flat, c3, c2, c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac3596e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.37076187133789 20.0 [9] 4 4\n",
      "7.297242164611816 7.0 [3] 8 8\n",
      "8.110270500183105 9.0 [7] 3 3\n",
      "8.37322998046875 6.0 [8] 9 5\n",
      "1.5587868690490723 2.0 [7] 9 8\n",
      "15.295458793640137 8.0 [1] 7 5\n",
      "6.854683876037598 3.0 [6] 7 7\n",
      "10.73036003112793 7.0 [2] 7 6\n",
      "3.931396245956421 0.0 [2] 7 2\n",
      "8.44135570526123 3.0 [4] 7 2\n",
      "5.3414998054504395 8.0 [0] 8 4\n",
      "2.6941730976104736 3.0 [7] 8 0\n",
      "1.7557027339935303 2.0 [2] 8 7\n",
      "3.102165460586548 2.0 [5] 9 7\n",
      "2.3847246170043945 4.0 [9] 2 7\n",
      "3.6294443607330322 0.0 [9] 2 9\n",
      "1.635027527809143 3.0 [2] 2 9\n",
      "1.798170804977417 3.0 [4] 2 2\n",
      "2.7127537727355957 3.0 [7] 9 4\n",
      "3.3734943866729736 3.0 [5] 8 4\n",
      "2.8225667476654053 0.0 [5] 9 5\n",
      "2.2785072326660156 4.0 [9] 4 5\n",
      "2.2637596130371094 9.0 [0] 2 9\n",
      "3.2505240440368652 3.0 [7] 2 0\n",
      "3.6455914974212646 0.0 [7] 2 7\n",
      "2.6040854454040527 3.0 [5] 0 7\n",
      "2.1916465759277344 4.0 [9] 2 5\n",
      "1.4896893501281738 4.0 [2] 2 9\n",
      "3.960935592651367 6.0 [1] 2 5\n",
      "1.4328631162643433 4.0 [0] 0 9\n",
      "2.4903674125671387 1.0 [1] 2 0\n",
      "1.7320274114608765 2.0 [2] 2 1\n",
      "1.8260191679000854 0.0 [0] 2 0\n",
      "2.5273144245147705 0.0 [0] 2 0\n",
      "2.3127403259277344 2.0 [1] 2 0\n",
      "1.9276490211486816 6.0 [6] 2 1\n",
      "4.452996253967285 5.0 [4] 2 2\n",
      "3.795926094055176 0.0 [4] 2 4\n",
      "1.9786489009857178 2.0 [1] 2 4\n",
      "2.798819065093994 3.0 [7] 2 1\n",
      "3.1613945960998535 9.0 [3] 2 1\n",
      "3.465120315551758 2.0 [4] 2 3\n",
      "3.3975372314453125 7.0 [8] 2 2\n",
      "2.0559163093566895 3.0 [1] 0 4\n",
      "2.7450003623962402 6.0 [5] 7 8\n",
      "2.005077600479126 3.0 [7] 2 4\n",
      "1.740438461303711 3.0 [9] 7 1\n",
      "2.6214945316314697 2.0 [5] 7 7\n",
      "1.4848662614822388 3.0 [7] 9 3\n",
      "1.4493281841278076 0.0 [7] 9 7\n",
      "0.8175762891769409 3.0 [9] 9 5\n",
      "5.29966402053833 4.0 [2] 9 9\n",
      "4.198430061340332 3.0 [1] 9 2\n",
      "9.935741424560547 2.0 [8] 9 1\n",
      "3.041614055633545 5.0 [0] 7 8\n",
      "1.4476466178894043 2.0 [5] 5 1\n",
      "3.047213077545166 3.0 [8] 5 5\n",
      "6.4104180335998535 3.0 [3] 5 2\n",
      "3.0017037391662598 3.0 [6] 5 8\n",
      "0.7456292510032654 3.0 [5] 5 6\n",
      "1.9985897541046143 3.0 [0] 5 5\n",
      "2.8446288108825684 2.0 [6] 5 5\n",
      "3.263726234436035 7.0 [4] 5 0\n",
      "2.0439231395721436 2.0 [0] 5 4\n",
      "2.222916603088379 2.0 [0] 5 6\n",
      "2.423067092895508 4.0 [1] 5 6\n",
      "2.00791072845459 0.0 [0] 5 0\n",
      "3.0446596145629883 4.0 [3] 0 0\n",
      "1.7846457958221436 1.0 [0] 0 5\n",
      "2.355013370513916 2.0 [4] 0 0\n",
      "3.6173441410064697 3.0 [9] 0 4\n",
      "2.077882766723633 2.0 [7] 0 4\n",
      "2.2251532077789307 2.0 [4] 0 0\n",
      "2.2256221771240234 3.0 [5] 0 4\n",
      "2.5521552562713623 5.0 [8] 0 3\n",
      "2.1802237033843994 3.0 [1] 0 7\n",
      "2.230644464492798 4.0 [2] 0 0\n",
      "2.3034942150115967 2.0 [4] 7 5\n",
      "2.2170052528381348 2.0 [1] 2 8\n",
      "2.297678232192993 2.0 [5] 1 4\n",
      "2.302217721939087 4.0 [6] 7 5\n",
      "2.334226369857788 2.0 [3] 7 2\n",
      "2.301204204559326 3.0 [6] 2 7\n",
      "2.1843225955963135 3.0 [2] 2 6\n",
      "2.2829365730285645 1.0 [6] 2 3\n",
      "3.176133155822754 2.0 [8] 2 6\n",
      "2.3114352226257324 6.0 [5] 2 8\n",
      "2.2544822692871094 2.0 [2] 2 5\n",
      "2.248934030532837 2.0 [1] 7 5\n",
      "2.0634512901306152 1.0 [1] 2 1\n",
      "2.429013252258301 3.0 [0] 2 1\n",
      "2.35459566116333 2.0 [0] 2 1\n",
      "2.686293125152588 2.0 [4] 2 1\n",
      "2.4611523151397705 3.0 [9] 2 1\n",
      "1.6856350898742676 1.0 [1] 2 0\n",
      "2.302076578140259 1.0 [0] 2 0\n",
      "2.6077322959899902 2.0 [8] 2 0\n",
      "2.324552297592163 2.0 [9] 2 0\n",
      "2.240790367126465 1.0 [0] 2 8\n",
      "2.172999382019043 1.0 [0] 2 1\n"
     ]
    }
   ],
   "source": [
    "torchmodel = Net()\n",
    "criterion = nn.NLLLoss()\n",
    "learning_rate = .00005\n",
    "optimizer = optim.SGD(torchmodel.parameters(), lr=learning_rate)\n",
    "\n",
    "c1 = ConvLayer(torchmodel.conv1.weight.detach().numpy().copy())\n",
    "c2 = ConvLayer(torchmodel.conv2.weight.detach().numpy().copy())\n",
    "c3 = ConvLayer(torchmodel.conv3.weight.detach().numpy().copy())\n",
    "fcl = LinearLayer(np.swapaxes(torchmodel.fcl.weight.detach().numpy().copy(), 0, 1))\n",
    "mymodel = CNN([c1, c2, c3], fcl, learning_rate)\n",
    "\n",
    "for i in range(100):\n",
    "    samp = np.random.randint(0, 50000)\n",
    "    shared_inp = np.asarray([x_train[samp]]).reshape((1, 3, 32, 32))\n",
    "    shared_out = [y_train[samp].item()]\n",
    "    \n",
    "    torch_lsm, torch_fcl, torch_flat, torch_c3, torch_c2, torch_c1 = torchmodel(torch.tensor(shared_inp, dtype=torch.float))\n",
    "    torch_pred = np.argmax(np.exp(torch_lsm.detach().numpy().copy()))\n",
    "    torch_loss = criterion(torch_lsm,  torch.tensor(shared_out))\n",
    "\n",
    "    p = mymodel.forward(shared_inp)\n",
    "    my_pred = np.argmax(np.exp(p))\n",
    "    dloss_dfclo, dloss_dfcli, dloss_dfcl, dloss_dfs, dloss_dos, my_loss = mymodel.backward(p, np.asarray([shared_out]))\n",
    "    torch_loss.backward()\n",
    "    optimizer.step()\n",
    "    print(torch_loss.item(), my_loss, shared_out, torch_pred, my_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9be2ba82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mymodel.eval(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c637c6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "shared_inp = x_train[0].reshape((1, 3, 32, 32))\n",
    "shared_out = [5]\n",
    "    \n",
    "torchmodel = Net()\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(torchmodel.parameters(), lr=0.001)\n",
    "torch_lsm, torch_fcl, torch_flat, torch_c3, torch_c2, torch_c1 = torchmodel(torch.tensor(shared_inp, dtype=torch.float))\n",
    "torch_loss = criterion(torch_lsm,  torch.tensor(shared_out))\n",
    "\n",
    "c1 = ConvLayer(torchmodel.conv1.weight.detach().numpy().copy())\n",
    "c2 = ConvLayer(torchmodel.conv2.weight.detach().numpy().copy())\n",
    "c3 = ConvLayer(torchmodel.conv3.weight.detach().numpy().copy())\n",
    "fcl = LinearLayer(np.swapaxes(torchmodel.fcl.weight.detach().numpy().copy(), 0, 1))\n",
    "mymodel = CNN([c1, c2, c3], fcl)\n",
    "targets = np.asarray([shared_out])\n",
    "p = mymodel.forward(shared_inp)\n",
    "dloss_dfclo, dloss_dfcli, dloss_dfcl, dloss_dfs, dloss_dos, myloss = mymodel.backward(p, np.asarray([shared_out]))\n",
    "\n",
    "torch_loss.backward()\n",
    "\n",
    "print(torch_loss.item(), myloss)\n",
    "\n",
    "'''\n",
    "'''\n",
    "\n",
    "fcl_grad = torch_fcl.grad.detach().numpy().copy()\n",
    "flat_grad = torch_flat.grad.detach().numpy().copy()\n",
    "torch_c3_grad = torch_c3.grad.detach().numpy().copy()\n",
    "torch_c2_grad = torch_c2.grad.detach().numpy().copy()\n",
    "torch_c1_grad = torch_c1.grad.detach().numpy().copy()\n",
    "print(fcl_grad.shape, flat_grad.shape, torch_c3_grad.shape, torch_c2_grad.shape, torch_c1_grad.shape)\n",
    "for i in range(len(torchmodel.stored_gradients)):\n",
    "    print(torchmodel.stored_gradients[i].shape)\n",
    "torchprev3 = (torchmodel.conv3.weight.detach().numpy().copy())\n",
    "torchprev2 = (torchmodel.conv2.weight.detach().numpy().copy())\n",
    "torchprev1 = (torchmodel.conv1.weight.detach().numpy().copy())\n",
    "optimizer.step()\n",
    "torchpost3 = (torchmodel.conv3.weight.detach().numpy().copy())\n",
    "torchpost2 = (torchmodel.conv2.weight.detach().numpy().copy())\n",
    "torchpost1 = (torchmodel.conv1.weight.detach().numpy().copy())\n",
    "grad3 = (torchprev3-torchpost3)*1000\n",
    "grad2 = (torchprev2-torchpost2)*1000\n",
    "grad1 = (torchprev1-torchpost1)*1000\n",
    "print(grad3[1, 0])\n",
    "print(dloss_dfs[0][1, 0])\n",
    "print(grad1[-1, -1])\n",
    "print(dloss_dfs[2][-1, -1])\n",
    "print(np.round(np.asarray(torchmodel.stored_gradients[1])[0, 0, 0:8, 0:8], 3)*1000)\n",
    "print(np.round(mymodel.conv_layers[-1].backpool_results[0][0, 0,  0:8, 0:8], 3)*1000)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
